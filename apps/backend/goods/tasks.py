import os
import json
import logging
import mysql.connector
import pandas as pd
import base64
from celery import shared_task
from django.db import transaction
from django.db.models import Q, Count
from mysql.connector import Error
from django.conf import settings
from api.models import User
from goods.indexers import ProductIndexer
from goods.models import Brand, Product, ProductGroup, ProductSubgroup, FileBlob, ProductFile
from datetime import datetime
from io import BytesIO
import hashlib
import mimetypes
import requests

logger = logging.getLogger(__name__)

mysql_config = {
    "host": os.getenv("MYSQL_HOST"),
    "port": os.getenv("MYSQL_PORT"),
    "user": os.getenv("MYSQL_USER"),
    "password": os.getenv("MYSQL_PASS"),
    "database": os.getenv("MYSQL_DB"),
    "charset": os.getenv("MYSQL_CHARSET"),
}


@shared_task
def update_products_from_mysql():
    """
    Celery-–∑–∞–¥–∞—á–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MySQL.
    –û–±–Ω–æ–≤–ª—è–µ—Ç –≥—Ä—É–ø–ø—ã —Ç–æ–≤–∞—Ä–æ–≤, –ø–æ–¥–≥—Ä—É–ø–ø—ã, –±—Ä–µ–Ω–¥—ã –∏ —Å–∞–º–∏ —Ç–æ–≤–∞—Ä—ã —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
    –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç product_manager –Ω–∞ –æ—Å–Ω–æ–≤–µ invoice_user –∏–∑ MySQL.
    """
    connection = None
    try:
        connection = mysql.connector.connect(**mysql_config)
        if connection.is_connected():
            cursor = connection.cursor(dictionary=True)

            # –í—ã–ø–æ–ª–Ω—è–µ–º SQL-–∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–≤–∞—Ä–∞—Ö
            cursor.execute(
                """
                SELECT
                    i.mainbase AS product_id,
                    m.tovmark AS product_name,
                    b.id AS brand_id,
                    m.brand,
                    m.mgroup AS subgroup_id,
                    g.tovmark AS subgroup_name,
                    g.typecode AS group_id,
                    g.tovgroup AS group_name,
                    w.complex AS complex_name,
                    w.description AS description,
                    i.timestamp AS last_bill,
                    inv.user AS invoice_user,
                    COALESCE(
                        (SELECT
                            CONCAT('{',
                                GROUP_CONCAT(
                                    CONCAT('"', tp.name, '": "', t.fact, '"')
                                    SEPARATOR ', '
                                ),
                            '}')
                         FROM metrinfo t
                         JOIN metrics tp ON t.metrics = tp.id
                         WHERE t.mainbase = m.id
                        ), '{}'
                    ) AS tech_params
                FROM invline i
                INNER JOIN (
                    SELECT
                        mainbase,
                        MAX(timestamp) AS max_timestamp
                    FROM invline
                    WHERE invoice > 0
                      AND mainbase > 0
                    GROUP BY mainbase
                ) latest ON i.mainbase = latest.mainbase
                   AND i.timestamp = latest.max_timestamp
                INNER JOIN mainbase m ON m.id = i.mainbase
                INNER JOIN mainwide w ON w.mainbase = m.id
                INNER JOIN brand b ON m.brand = b.name
                INNER JOIN invoice inv ON inv.id = i.invoice
                INNER JOIN groupsb g ON m.mgroup = g.mgroup
                WHERE inv.user <> '';
            """
            )

            product_data = cursor.fetchall()

            if not product_data:
                logger.warning("MySQL-–∑–∞–ø—Ä–æ—Å –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã—Ö")
                return "–ù–µ –ø–æ–ª—É—á–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"
        else:
            logger.error("MySQL-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å MySQL"
    except Error as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ MySQL: {e}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}"
    finally:
        if connection and connection.is_connected():
            cursor.close()
            connection.close()
            logger.info("MySQL-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ")

    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –æ—Ç—á–µ—Ç–∞
    groups_created = 0
    groups_updated = 0
    subgroups_created = 0
    subgroups_updated = 0
    brands_created = 0
    brands_updated = 0
    products_created = 0
    products_updated = 0
    managers_linked = 0
    params_updated = 0

    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö product-–º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –∏ —Å–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å {old_db_name: user_instance}
        product_managers = {
            pm.old_db_name: pm for pm in User.objects.filter(role=User.Role.PURCHASER)
        }

        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Django –º–æ–¥–µ–ª—è—Ö
        with transaction.atomic():
            # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            processed_groups = {}
            processed_subgroups = {}
            processed_brands = {}

            for item in product_data:
                # 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã —Ç–æ–≤–∞—Ä–æ–≤
                if item["group_id"] not in processed_groups:
                    group, group_created = (
                        ProductGroup.objects.update_or_create(
                            ext_id=item["group_id"],
                            defaults={"name": item["group_name"]},
                        )
                    )
                    processed_groups[item["group_id"]] = group
                    if group_created:
                        groups_created += 1
                    else:
                        groups_updated += 1
                else:
                    group = processed_groups[item["group_id"]]

                # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–¥–≥—Ä—É–ø–ø—ã —Ç–æ–≤–∞—Ä–æ–≤
                if item["subgroup_id"] not in processed_subgroups:
                    subgroup, subgroup_created = (
                        ProductSubgroup.objects.update_or_create(
                            ext_id=item["subgroup_id"],
                            defaults={
                                "name": item["subgroup_name"],
                                "group": group,
                            },
                        )
                    )
                    processed_subgroups[item["subgroup_id"]] = subgroup
                    if subgroup_created:
                        subgroups_created += 1
                    else:
                        subgroups_updated += 1
                else:
                    subgroup = processed_subgroups[item["subgroup_id"]]

                # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—Ä–µ–Ω–¥–∞
                if item["brand_id"] not in processed_brands:
                    brand, brand_created = Brand.objects.update_or_create(
                        ext_id=item["brand_id"],
                        defaults={"name": item["brand"]},
                    )
                    processed_brands[item["brand_id"]] = brand
                    if brand_created:
                        brands_created += 1
                    else:
                        brands_updated += 1
                else:
                    brand = processed_brands[item["brand_id"]]

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º product-–º–µ–Ω–µ–¥–∂–µ—Ä–∞ –¥–ª—è —Ç–æ–≤–∞—Ä–∞
                product_manager = None
                if (
                    item["invoice_user"]
                    and item["invoice_user"] in product_managers
                ):
                    product_manager = product_managers[item["invoice_user"]]

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                try:
                    tech_params = json.loads(item["tech_params"])
                    has_params = len(tech_params) > 0
                except (json.JSONDecodeError, TypeError):
                    tech_params = {}
                    has_params = False

                # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–≤–∞—Ä–∞
                product, product_created = Product.objects.update_or_create(
                    ext_id=item["product_id"],
                    defaults={
                        "name": item["product_name"],
                        "subgroup": subgroup,
                        "brand": brand,
                        "product_manager": product_manager,
                        "tech_params": tech_params,
                        "complex_name": item["complex_name"],
                        "description": item["description"],
                    },
                )

                if product_created:
                    products_created += 1
                else:
                    products_updated += 1

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤, –∫ –∫–æ—Ç–æ—Ä—ã–º –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                if has_params:
                    params_updated += 1

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤, –∫ –∫–æ—Ç–æ—Ä—ã–º –±—ã–ª –ø—Ä–∏–≤—è–∑–∞–Ω –º–µ–Ω–µ–¥–∂–µ—Ä
                if product_manager:
                    managers_linked += 1

        logger.info(
            f"–û–±–Ω–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–æ–≤: –≥—Ä—É–ø–ø—ã {groups_updated}/{groups_created}, "
            f"–ø–æ–¥–≥—Ä—É–ø–ø—ã {subgroups_updated}/{subgroups_created}, "
            f"–±—Ä–µ–Ω–¥—ã {brands_updated}/{brands_created}, "
            f"—Ç–æ–≤–∞—Ä—ã {products_updated}/{products_created}, "
            f"–ø—Ä–∏–≤—è–∑–∞–Ω–æ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤: {managers_linked}, "
            f"–æ–±–Ω–æ–≤–ª–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {params_updated}"
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–µ Django: {e}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}"

    return (
        f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö:\n"
        f"–ì—Ä—É–ø–ø—ã: {groups_updated} (—Å–æ–∑–¥–∞–Ω–æ: {groups_created})\n"
        f"–ü–æ–¥–≥—Ä—É–ø–ø—ã: {subgroups_updated} (—Å–æ–∑–¥–∞–Ω–æ: {subgroups_created})\n"
        f"–ë—Ä–µ–Ω–¥—ã: {brands_updated} (—Å–æ–∑–¥–∞–Ω–æ: {brands_created})\n"
        f"–¢–æ–≤–∞—Ä—ã: {products_updated} (—Å–æ–∑–¥–∞–Ω–æ: {products_created})\n"
        f"–ü—Ä–∏–≤—è–∑–∞–Ω–æ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤: {managers_linked}\n"
        f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {params_updated}"
    )


def _ensure_blob_from_response(resp, filename_hint: str | None) -> FileBlob:
    """–ß–∏—Ç–∞–µ—Ç HTTP-–æ—Ç–≤–µ—Ç –æ–¥–∏–Ω —Ä–∞–∑: –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —Å—á–∏—Ç–∞–µ—Ç SHA-256 –∏ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ."""
    content_type = resp.headers.get("Content-Type", "")
    buffer = BytesIO()
    hasher = hashlib.sha256()
    total = 0
    for chunk in resp.iter_content(chunk_size=8192):
        if not chunk:
            continue
        hasher.update(chunk)
        buffer.write(chunk)
        total += len(chunk)
    sha = hasher.hexdigest()

    # –î–µ–¥—É–ø –ø–æ sha
    existing = FileBlob.objects.filter(sha256=sha).first()
    if existing:
        return existing

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –∏ MIME
    filename = filename_hint or "file"
    cd = resp.headers.get("Content-Disposition")
    if cd and "filename=" in cd:
        filename = cd.split("filename=")[-1].strip('"')
    mime = content_type or (mimetypes.guess_type(filename)[0] or "application/octet-stream")

    from django.core.files.base import ContentFile

    buffer.seek(0)
    blob = FileBlob(sha256=sha, size=total, mime_type=mime)
    blob.file.save(name=filename, content=ContentFile(buffer.read()), save=True)
    return blob


def _fetch_zip2002_file(product_ext_id: str, file_type: str) -> tuple[FileBlob | None, str | None]:
    # file_type: "datasheet" -> type=file_p, "drawing" -> type=file_i
    if file_type == ProductFile.FileType.DATASHEET:
        url = f"https://www.zip-2002.ru/zip-download.php/?type=file_p&id={product_ext_id}"
    else:
        url = f"https://www.zip-2002.ru/zip-download.php/?type=file_i&id={product_ext_id}"

    try:
        resp = requests.get(url, stream=True, timeout=30)
        if resp.status_code == 404:
            return None, url
        resp.raise_for_status()
        blob = _ensure_blob_from_response(resp, filename_hint=None)
        return blob, url
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –¥–ª—è id={product_ext_id} ({file_type}): {e}")
        return None, url


@shared_task
def download_all_datasheets(batch_size: int = 500):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—à–∏—Ç—ã –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Ö –µ—â—ë –Ω–µ—Ç.
    –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ FileBlob.sha256 –∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å ProductFile(product, file_type).
    """
    qs = (
        Product.objects.exclude(ext_id__isnull=True)
        .exclude(ext_id__exact="")
        .select_related("brand", "subgroup")
    )
    processed = 0
    created = 0
    skipped = 0
    for product in qs.iterator(chunk_size=batch_size):
        # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –¥–∞—Ç–∞—â–∏—Ç
        if ProductFile.objects.filter(product=product, file_type=ProductFile.FileType.DATASHEET).exists():
            skipped += 1
            continue
        blob, src = _fetch_zip2002_file(product.ext_id, ProductFile.FileType.DATASHEET)
        if blob:
            try:
                ProductFile.objects.create(
                    product=product,
                    blob=blob,
                    file_type=ProductFile.FileType.DATASHEET,
                    source_url=src or "",
                )
                created += 1
            except Exception as e:
                logger.info(f"–§–∞–π–ª —É–∂–µ –ø—Ä–∏–≤—è–∑–∞–Ω –∏–ª–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç: {e}")
        processed += 1
    return {"processed": processed, "created": created, "skipped": skipped}


@shared_task
def download_all_drawings(batch_size: int = 500):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —á–µ—Ä—Ç–µ–∂–∏ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Ö –µ—â—ë –Ω–µ—Ç.
    """
    qs = (
        Product.objects.exclude(ext_id__isnull=True)
        .exclude(ext_id__exact="")
        .select_related("brand", "subgroup")
    )
    processed = 0
    created = 0
    skipped = 0
    for product in qs.iterator(chunk_size=batch_size):
        if ProductFile.objects.filter(product=product, file_type=ProductFile.FileType.DRAWING).exists():
            skipped += 1
            continue
        blob, src = _fetch_zip2002_file(product.ext_id, ProductFile.FileType.DRAWING)
        if blob:
            try:
                ProductFile.objects.create(
                    product=product,
                    blob=blob,
                    file_type=ProductFile.FileType.DRAWING,
                    source_url=src or "",
                )
                created += 1
            except Exception as e:
                logger.info(f"–§–∞–π–ª —É–∂–µ –ø—Ä–∏–≤—è–∑–∞–Ω –∏–ª–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç: {e}")
        processed += 1
    return {"processed": processed, "created": created, "skipped": skipped}


@shared_task
def export_parts_to_csv():
    """
    Celery-–∑–∞–¥–∞—á–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–µ—Ç–∞–ª–µ–π –±—Ä–µ–Ω–¥–æ–≤ RUICHI, SZC, ZTM-ELECTRO
    –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MySQL –±–∞–∑—ã –≤ CSV —Ñ–∞–π–ª.

    CSV —Ñ–∞–π–ª –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ (—Ä—è–¥–æ–º —Å manage.py).
    """
    import csv
    from datetime import datetime
    
    connection = None
    try:
        connection = mysql.connector.connect(**mysql_config)
        if connection.is_connected():
            cursor = connection.cursor(dictionary=True)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            query = """
            SELECT
                m.id,
                m.tovmark AS part,
                m.brand,
                m.excode AS img_code,
                w.subgroup_ruelcom AS subgroup,
                w.complex,
                COALESCE(
                    (SELECT
                        CONCAT('{',
                            GROUP_CONCAT(
                                CONCAT('"', tp.name, '": "', t.fact, '"')
                                SEPARATOR ', '
                            ),
                        '}')
                     FROM metrinfo t
                     JOIN metrics tp ON t.metrics = tp.id
                     WHERE t.mainbase = i.mainbase
                    ), '{}'
                ) AS tech_params
            FROM mainbase m
            INNER JOIN mainwide w ON w.mainbase = m.id
            WHERE m.brand IN ('RUICHI', 'SZC', 'ZTM-ELECTRO')
            AND m.ruelsite <> 0;
            """

            cursor.execute(query)
            parts_data = cursor.fetchall()

            if not parts_data:
                logger.warning("–ó–∞–ø—Ä–æ—Å –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã—Ö")
                return "–î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        else:
            logger.error("MySQL-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return "–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"

    except Error as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ MySQL: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"
    finally:
        if connection and connection.is_connected():
            cursor.close()
            connection.close()
            logger.info("MySQL —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è manage.py
    project_dir = settings.BASE_DIR

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    csv_filename = os.path.join(project_dir, f'parts_export_{timestamp}.csv')

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª
    try:
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            if parts_data:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á–∏ –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
                fieldnames = parts_data[0].keys()
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

                writer.writeheader()
                writer.writerows(parts_data)

                logger.info(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {csv_filename}")
                return f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(parts_data)} –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª {os.path.basename(csv_filename)} –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞"
            else:
                return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ CSV —Ñ–∞–π–ª: {e}")


@shared_task
def index_products_atomically():
    """
    –ó–∞–¥–∞—á–∞ –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ MeiliSearch.
    –û—á–∏—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –∏ —Å–æ–∑–¥–∞–µ—Ç –µ–≥–æ –∑–∞–Ω–æ–≤–æ.
    """
    try:
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –ø–æ–ª–Ω—É—é –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Ç–æ–≤–∞—Ä–æ–≤ –≤ MeiliSearch")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–æ–≤–∞—Ä—ã
        products = Product.objects.select_related('brand', 'subgroup__group', 'product_manager').all()
        
        # –û—á–∏—â–∞–µ–º –∏–Ω–¥–µ–∫—Å –∏ —Å–æ–∑–¥–∞–µ–º –∑–∞–Ω–æ–≤–æ
        ProductIndexer.index_all_atomically()
        
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {products.count()} —Ç–æ–≤–∞—Ä–æ–≤ –≤ MeiliSearch")
        return f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {products.count()} —Ç–æ–≤–∞—Ä–æ–≤"
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤: {e}")
        raise


@shared_task
def index_products(product_ids):
    """
    –ó–∞–¥–∞—á–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∏—Ö ID.
    """
    try:
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Ç–æ–≤–∞—Ä–æ–≤ —Å ID: {product_ids}")
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—è Q-–æ–±—ä–µ–∫—Ç
        ProductIndexer.index_from_query(Q(pk__in=product_ids))
        
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(product_ids)} —Ç–æ–≤–∞—Ä–æ–≤")
        return f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(product_ids)} —Ç–æ–≤–∞—Ä–æ–≤"
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ {product_ids}: {e}")
        raise


@shared_task
def unindex_products(product_ids):
    """
    –ó–∞–¥–∞—á–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ MeiliSearch.
    """
    try:
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞: {product_ids}")
        
        # –£–¥–∞–ª—è–µ–º —Ç–æ–≤–∞—Ä—ã –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
        ProductIndexer.unindex_multiple(product_ids)
        
        logger.info(f"–£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ {len(product_ids)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞")
        return f"–£–¥–∞–ª–µ–Ω–æ {len(product_ids)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞"
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ {product_ids}: {e}")
        raise


@shared_task
def prom_import_brands(username: str | None = None, password: str | None = None, headless: bool = True):
    """
    –õ–æ–≥–∏–Ω–∏—Ç—Å—è –Ω–∞ https://office.promelec.ru/ –∏ –ø–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É "–í—Å–µ –±—Ä–µ–Ω–¥—ã",
    –∑–∞—Ç–µ–º —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –±—Ä–µ–Ω–¥—ã –≤ –º–æ–¥–µ–ª—å stock.CompetitorBrand –¥–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ Promelec
    (upsert –ø–æ –ø–∞—Ä–µ competitor+name, –æ–±–Ω–æ–≤–ª—è—è ext_id).

    Args:
        username: –õ–æ–≥–∏–Ω PROM (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –±–µ—Ä—ë—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è PROM_LOGIN)
        password: –ü–∞—Ä–æ–ª—å PROM (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –±–µ—Ä—ë—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è PROM_PASSWORD)
        headless: –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞ Playwright –≤ headless-—Ä–µ–∂–∏–º–µ

    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö/–æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
    """
    import re
    import asyncio
    from stock.clients.prom import PromClient, PromAuthError
    from stock.models import Competitor, CompetitorBrand

    user = username or os.getenv("PROM_LOGIN")
    pwd = password or os.getenv("PROM_PASSWORD")
    if not user or not pwd:
        logger.error("–ù–µ –∑–∞–¥–∞–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ PROM_LOGIN/PROM_PASSWORD –∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∑–∞–¥–∞—á–∏")
        return {"success": False, "error": "PROM_LOGIN/PROM_PASSWORD –Ω–µ –∑–∞–¥–∞–Ω—ã"}

    async def _run() -> dict:
        async with PromClient(headless=headless) as client:
            await client.login_and_get_session(user, pwd)
            url = "https://office.promelec.ru/all-brands"
            html, soup = await client.get_and_parse(url)
            anchors = soup.select("section.all-brands a[href^='/all-brands/']")
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ –º–∞–ø—É name -> ext_id (–∏–º—è ‚Äî –∫–ª—é—á —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –≤ CompetitorBrand)
            items: dict[str, str] = {}
            for a in anchors:
                name_raw = a.get_text(" ", strip=True)
                name = name_raw.strip()
                href = a.get("href") or ""
                m = re.search(r"/all-brands/(\d+)", href)
                if not name or not m:
                    continue
                ext_id = m.group(1)
                items[name] = ext_id
            return {"items": items, "count": len(items)}

    try:
        result = asyncio.run(_run())
    except PromAuthError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ PROM: {e}")
        return {"success": False, "error": str(e)}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –±—Ä–µ–Ω–¥–æ–≤: {e}", exc_info=True)
        return {"success": False, "error": str(e)}

    # –ò—â–µ–º/—Å–æ–∑–¥–∞—ë–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –¥–ª—è PROM
    competitor, _ = Competitor.objects.get_or_create(
        name="Promelec",
        defaults={
            "site_url": "",
            "b2b_site_url": "https://office.promelec.ru/",
            "is_active": True,
        },
    )
    # –û–±–Ω–æ–≤–∏–º b2b_site_url, –µ—Å–ª–∏ –æ–Ω –ø—É—Å—Ç–æ–π
    if not competitor.b2b_site_url:
        competitor.b2b_site_url = "https://office.promelec.ru/"
        competitor.save(update_fields=["b2b_site_url"])

    created = 0
    updated = 0
    skipped = 0
    with transaction.atomic():
        for name, ext_id in result["items"].items():
            obj, is_created = CompetitorBrand.objects.update_or_create(
                competitor=competitor,
                name=name,
                defaults={"ext_id": str(ext_id), "is_active": True},
            )
            if is_created:
                created += 1
            else:
                changed_fields: list[str] = []
                if obj.ext_id != str(ext_id):
                    obj.ext_id = str(ext_id)
                    changed_fields.append("ext_id")
                if not obj.is_active:
                    obj.is_active = True
                    changed_fields.append("is_active")
                if changed_fields:
                    obj.save(update_fields=changed_fields)
                    updated += 1
                else:
                    skipped += 1

    msg = {"success": True, "total": result["count"], "created": created, "updated": updated, "skipped": skipped}
    logger.info(f"–ò–º–ø–æ—Ä—Ç –±—Ä–µ–Ω–¥–æ–≤ PROM (CompetitorBrand) –∑–∞–≤–µ—Ä—à—ë–Ω: {msg}")
    return msg

@shared_task
def reindex_products_smart():
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.
    
    –≠—Ç–∞ –∑–∞–¥–∞—á–∞:
    1. –û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–π –∏–Ω–¥–µ–∫—Å
    2. –ü—Ä–∏–º–µ–Ω—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    3. –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–æ–≤–∞—Ä—ã
    4. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    """
    try:
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Ç–æ–≤–∞—Ä–æ–≤ –≤ MeiliSearch")
        
        # –ò–º–ø–æ—Ä—Ç –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        from meilisearch import Client
        from django.conf import settings
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ MeiliSearch
        client = Client(settings.MEILISEARCH_HOST, settings.MEILISEARCH_API_KEY)
        index_name = ProductIndexer.index_name()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–æ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        products_count = Product.objects.count()
        st_products_count = Product.objects.filter(brand__name__icontains="ST").count()
        
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –ë–î:")
        logger.info(f"   ‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {products_count}")
        logger.info(f"   ‚Ä¢ ST —Ç–æ–≤–∞—Ä–æ–≤: {st_products_count}")
        
        # 1. –°–æ–∑–¥–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        logger.info("üîß –û–±–Ω–æ–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–¥–µ–∫—Å–∞...")
        index = client.index(index_name)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ ProductIndexer
        settings_update = ProductIndexer.SETTINGS
        logger.info(f"   ‚Ä¢ –ü—Ä–∏–º–µ–Ω—è–µ–º filterable attributes: {settings_update['filterableAttributes']}")
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–¥–µ–∫—Å–∞
            task = index.update_settings(settings_update)
            client.wait_for_task(task.task_uid)
            logger.info("   ‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–¥–µ–∫—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {e}")
        
        # 2. –û—á–∏—â–∞–µ–º –∏–Ω–¥–µ–∫—Å –∏ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
        logger.info("üóëÔ∏è  –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–π –∏–Ω–¥–µ–∫—Å...")
        ProductIndexer.index_all_atomically()
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏...")
        
        # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        import time
        time.sleep(2)
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ
            index_info = index.get_stats()
            indexed_count = index_info.number_of_documents
            
            logger.info(f"‚úÖ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            logger.info(f"   ‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ: {indexed_count}")
            logger.info(f"   ‚Ä¢ –ü–æ–∫—Ä—ã—Ç–∏–µ: {(indexed_count/products_count*100):.1f}%" if products_count > 0 else "   ‚Ä¢ –ü–æ–∫—Ä—ã—Ç–∏–µ: N/A")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ ST —Ç–æ–≤–∞—Ä–æ–≤
            test_result = index.search("ST", {"filter": 'brand_name = "ST"', "limit": 1})
            st_found = test_result.estimated_total_hits
            logger.info(f"   ‚Ä¢ ST —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–∏ —Ç–µ—Å—Ç–µ: {st_found}")
            
            success_message = f"–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count} —Ç–æ–≤–∞—Ä–æ–≤. ST —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {st_found}"
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞: {e}")
            success_message = f"–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"
        
        logger.info(f"üéâ {success_message}")
        return success_message
        
    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤: {e}"
        logger.error(f"‚ùå {error_msg}")
        raise 


@shared_task
def export_products_by_typecode(typecode):
    """
    Celery-–∑–∞–¥–∞—á–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ ID –ø–æ–¥–≥—Ä—É–ø–ø—ã (typecode) –≤ Excel —Ñ–∞–π–ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –±–∏–Ω–∞—Ä–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —Ñ–∞–π–ª–∞ –≤–º–µ—Å—Ç–æ –ø—É—Ç–∏.
    """
    connection = None
    try:
        connection = mysql.connector.connect(**mysql_config)
        if connection.is_connected():
            cursor = connection.cursor(dictionary=True)
           
            # –í—ã–ø–æ–ª–Ω—è–µ–º SQL –∑–∞–ø—Ä–æ—Å —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ typecode
            query = """
            SELECT
                mainbase.id AS '–ê—Ä—Ç–∏–∫—É–ª',
                CASE 
                    WHEN LEFT(TRIM(REVERSE(gg.tovgroup)), 1) = '*' 
                    THEN TRIM(REVERSE(SUBSTRING(TRIM(REVERSE(gg.tovgroup)), 2))) 
                    ELSE gg.tovgroup 
                END AS '–ì—Ä—É–ø–ø–∞',
                gg.tovmark AS '–ü–æ–¥–≥—Ä—É–ø–ø–∞',
                mainwide.head AS '–¢–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏',
                mainwide.brand AS '–ë—Ä—ç–Ω–¥',
                mainbase.tovmark AS '–ü—Ä–æ—Å—Ç–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ',
                mainwide.complex AS '–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ',
                mainwide.description AS '–û–ø–∏—Å–∞–Ω–∏–µ',
                mainwide.keywords AS '–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞'
            FROM groupsb gg
            JOIN mainbase ON mainbase.mgroup = gg.mgroup
            LEFT JOIN mainwide ON mainwide.mainbase = mainbase.id
            WHERE gg.mgroup = %s
            AND mainbase.ruelsite <> 0
            ORDER BY 3, 4, 7
            """
            cursor.execute(query, (typecode,))
            products = cursor.fetchall()
           
            if not products:
                logger.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è typecode={typecode}")
                return {
                    'success': False,
                    'error': f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ typecode: {typecode}"
                }
        else:
            logger.error("MySQL-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return {
                'success': False,
                'error': "–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"
            }
    except Error as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ MySQL: {e}")
        return {
            'success': False,
            'error': f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
        }
    finally:
        if connection and connection.is_connected():
            cursor.close()
            connection.close()
   
    # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(products)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É @rev
        if '@rev' in df.columns:
            df = df.drop(columns=['@rev'])
        
        # –í–º–µ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞ –¥–∏—Å–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º BytesIO
        excel_buffer = BytesIO()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä
        df.to_excel(excel_buffer, sheet_name='–¢–æ–≤–∞—Ä—ã', index=False)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±—É—Ñ–µ—Ä–∞
        excel_buffer.seek(0)
        file_data = excel_buffer.getvalue()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ base64 –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ —á–µ—Ä–µ–∑ JSON
        encoded_data = base64.b64encode(file_data).decode('utf-8')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"products_typecode_{typecode}_{timestamp}.xlsx"
        
        logger.info(f"–°–æ–∑–¥–∞–Ω Excel —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è typecode={typecode} —Å {len(products)} –∑–∞–ø–∏—Å—è–º–∏")
        
        return {
            'success': True,
            'filename': filename,
            'data': encoded_data,
            'records': len(products)
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel-—Ñ–∞–π–ª–∞: {e}")
        return {
            'success': False,
            'error': f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel-—Ñ–∞–π–ª–∞: {str(e)}"
        }


@shared_task
def export_products_by_filters(subgroup_ids=None, brand_names=None, only_two_params=False, no_description=False):
    """
    Celery-–∑–∞–¥–∞—á–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤ —Ç–æ–≤–∞—Ä–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π 
    –ø–æ –ø–æ–¥–≥—Ä—É–ø–ø–∞–º, –±—Ä–µ–Ω–¥–∞–º, –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –Ω–∞–ª–∏—á–∏—é –æ–ø–∏—Å–∞–Ω–∏—è –≤ Excel —Ñ–∞–π–ª.
    
    Args:
        subgroup_ids (list): –°–ø–∏—Å–æ–∫ ext_id –ø–æ–¥–≥—Ä—É–ø–ø –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å None –¥–ª—è –≤—Å–µ—Ö)
        brand_names (list): –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –±—Ä–µ–Ω–¥–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å None –¥–ª—è –≤—Å–µ—Ö)  
        only_two_params (bool): –ï—Å–ª–∏ True, —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã —Å –¥–≤—É–º—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        no_description (bool): –ï—Å–ª–∏ True, —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è
    
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —ç–∫—Å–ø–æ—Ä—Ç–∞ –∏ –±–∏–Ω–∞—Ä–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —Ñ–∞–π–ª–∞
    """
    connection = None
    try:
        connection = mysql.connector.connect(**mysql_config)
        if connection.is_connected():
            cursor = connection.cursor(dictionary=True)
           
            # –ë–∞–∑–æ–≤—ã–π SQL –∑–∞–ø—Ä–æ—Å
            base_query = """
            SELECT
                mainbase.id AS '–ê—Ä—Ç–∏–∫—É–ª',
                CASE 
                    WHEN LEFT(TRIM(REVERSE(gg.tovgroup)), 1) = '*' 
                    THEN TRIM(REVERSE(SUBSTRING(TRIM(REVERSE(gg.tovgroup)), 2))) 
                    ELSE gg.tovgroup 
                END AS '–ì—Ä—É–ø–ø–∞',
                gg.tovmark AS '–ü–æ–¥–≥—Ä—É–ø–ø–∞',
                mainwide.head AS '–¢–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏',
                mainwide.brand AS '–ë—Ä—ç–Ω–¥',
                mainbase.tovmark AS '–ü—Ä–æ—Å—Ç–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ',
                mainwide.complex AS '–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ',
                mainwide.description AS '–û–ø–∏—Å–∞–Ω–∏–µ',
                mainwide.keywords AS '–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞'
            FROM groupsb gg
            JOIN mainbase ON mainbase.mgroup = gg.mgroup
            LEFT JOIN mainwide ON mainwide.mainbase = mainbase.id
            WHERE mainbase.ruelsite <> 0
            """
            
            # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–ª–æ–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            where_conditions = []
            query_params = []
            
            if subgroup_ids:
                # –§–∏–ª—å—Ç—Ä –ø–æ –ø–æ–¥–≥—Ä—É–ø–ø–∞–º
                placeholders = ', '.join(['%s'] * len(subgroup_ids))
                where_conditions.append(f"gg.mgroup IN ({placeholders})")
                query_params.extend(subgroup_ids)
            
            if brand_names:
                # –§–∏–ª—å—Ç—Ä –ø–æ –±—Ä–µ–Ω–¥–∞–º
                placeholders = ', '.join(['%s'] * len(brand_names))
                where_conditions.append(f"mainwide.brand IN ({placeholders})")
                query_params.extend(brand_names)
            
            if only_two_params:
                # –§–∏–ª—å—Ç—Ä –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Ä–æ–≤–Ω–æ 2)
                tech_params_filter = """
                    (SELECT COUNT(*) 
                     FROM metrinfo t 
                     JOIN metrics tp ON t.metrics = tp.id 
                     WHERE t.mainbase = mainbase.id) = 2
                """
                where_conditions.append(tech_params_filter)
            
            if no_description:
                # –§–∏–ª—å—Ç—Ä –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è (–ø—É—Å—Ç–æ–µ –∏–ª–∏ NULL –æ–ø–∏—Å–∞–Ω–∏–µ)
                no_description_filter = "(mainwide.description IS NULL OR TRIM(mainwide.description) = '')"
                where_conditions.append(no_description_filter)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            if where_conditions:
                query = base_query + " AND " + " AND ".join(where_conditions)
            else:
                query = base_query
                
            query += " ORDER BY 3, 4, 7"
            
            logger.info(f"–í—ã–ø–æ–ª–Ω—è–µ–º SQL –∑–∞–ø—Ä–æ—Å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: subgroups={subgroup_ids}, brands={brand_names}, only_two_params={only_two_params}, no_description={no_description}")
            cursor.execute(query, query_params)
            products = cursor.fetchall()
           
            if not products:
                logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏")
                return {
                    'success': False,
                    'error': "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏"
                }
        else:
            logger.error("MySQL-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return {
                'success': False,
                'error': "–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"
            }
    except Error as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ MySQL: {e}")
        return {
            'success': False,
            'error': f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
        }
    finally:
        if connection and connection.is_connected():
            cursor.close()
            connection.close()
   
    # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(products)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É @rev –µ—Å–ª–∏ –µ—Å—Ç—å
        if '@rev' in df.columns:
            df = df.drop(columns=['@rev'])
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º BytesIO –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –≤ –ø–∞–º—è—Ç–∏
        excel_buffer = BytesIO()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä
        df.to_excel(excel_buffer, sheet_name='–¢–æ–≤–∞—Ä—ã', index=False)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±—É—Ñ–µ—Ä–∞
        excel_buffer.seek(0)
        file_data = excel_buffer.getvalue()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ base64 –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ —á–µ—Ä–µ–∑ JSON
        encoded_data = base64.b64encode(file_data).decode('utf-8')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # –°–æ–∑–¥–∞–µ–º –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        filename_parts = ["products"]
        if subgroup_ids:
            filename_parts.append(f"subgroups_{len(subgroup_ids)}")
        if brand_names:
            filename_parts.append(f"brands_{len(brand_names)}")
        if only_two_params:
            filename_parts.append("2params")
        if no_description:
            filename_parts.append("no_desc")
        filename_parts.append(timestamp)
        
        filename = f"{'_'.join(filename_parts)}.xlsx"
        
        logger.info(f"–°–æ–∑–¥–∞–Ω Excel —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏ —Å {len(products)} –∑–∞–ø–∏—Å—è–º–∏. –§–∏–ª—å—Ç—Ä—ã: –ø–æ–¥–≥—Ä—É–ø–ø—ã={subgroup_ids}, –±—Ä–µ–Ω–¥—ã={brand_names}, only_two_params={only_two_params}, no_description={no_description}")
        
        return {
            'success': True,
            'filename': filename,
            'data': encoded_data,
            'records': len(products),
            'filters': {
                'subgroups': subgroup_ids or [],
                'brands': brand_names or [],
                'only_two_params': only_two_params,
                'no_description': no_description
            }
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel-—Ñ–∞–π–ª–∞: {e}")
        return {
            'success': False,
            'error': f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel-—Ñ–∞–π–ª–∞: {str(e)}"
        }


@shared_task
def assign_product_managers():
    """
    Celery-–∑–∞–¥–∞—á–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ —Ç–æ–≤–∞—Ä–∞–º –±–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞.

    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
    2. –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∏—Ö –ø–æ –ø–æ–¥–≥—Ä—É–ø–ø–∞–º
    3. –î–ª—è –∫–∞–∂–¥–æ–π –ø–æ–¥–≥—Ä—É–ø–ø—ã –Ω–∞—Ö–æ–¥–∏—Ç –º–µ–Ω–µ–¥–∂–µ—Ä–∞, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —ç—Ç–æ–π –ø–æ–¥–≥—Ä—É–ø–ø–µ
    4. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —ç—Ç–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –Ω–∞ —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –≤ –¥–∞–Ω–Ω–æ–π –ø–æ–¥–≥—Ä—É–ø–ø–µ
    """
    try:
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ —Ç–æ–≤–∞—Ä–∞–º")

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ä–æ–ª—å—é PURCHASER)
        managers = User.objects.filter(role=User.Role.PURCHASER)
        if not managers.exists():
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –¥–ª—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è")
            return "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –¥–ª—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è"

        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
        products_without_manager = Product.objects.filter(product_manager__isnull=True).select_related('subgroup')
        if not products_without_manager.exists():
            logger.info("–í—Å–µ —Ç–æ–≤–∞—Ä—ã —É–∂–µ –∏–º–µ—é—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤")
            return "–í—Å–µ —Ç–æ–≤–∞—Ä—ã —É–∂–µ –∏–º–µ—é—Ç –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤"

        total_products = products_without_manager.count()
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {total_products} —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã –ø–æ –ø–æ–¥–≥—Ä—É–ø–ø–∞–º
        products_by_subgroup = {}
        for product in products_without_manager:
            subgroup_id = product.subgroup_id
            if subgroup_id not in products_by_subgroup:
                products_by_subgroup[subgroup_id] = []
            products_by_subgroup[subgroup_id].append(product)

        logger.info(f"–¢–æ–≤–∞—Ä—ã —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω—ã –ø–æ {len(products_by_subgroup)} –ø–æ–¥–≥—Ä—É–ø–ø–∞–º")

        assigned_count = 0

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –ø–æ–¥–≥—Ä—É–ø–ø—É
        with transaction.atomic():
            for subgroup_id, products in products_by_subgroup.items():
                # –ù–∞—Ö–æ–¥–∏–º –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–æ–≤–∞—Ä–æ–≤ –≤ —ç—Ç–æ–π –ø–æ–¥–≥—Ä—É–ø–ø–µ
                manager_stats = (
                    Product.objects.filter(subgroup_id=subgroup_id, product_manager__isnull=False)
                    .values('product_manager')
                    .annotate(product_count=Count('id'))
                    .order_by('-product_count')
                )

                if manager_stats.exists():
                    # –ë–µ—Ä–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–æ–≤–∞—Ä–æ–≤
                    top_manager_id = manager_stats.first()['product_manager']
                    try:
                        top_manager = User.objects.get(id=top_manager_id, role=User.Role.PURCHASER)
                    except User.DoesNotExist:
                        logger.warning(f"–ú–µ–Ω–µ–¥–∂–µ—Ä —Å ID {top_manager_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–¥–≥—Ä—É–ø–ø—É {subgroup_id}")
                        continue

                    # –ù–∞–∑–Ω–∞—á–∞–µ–º —ç—Ç–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –≤—Å–µ–º —Ç–æ–≤–∞—Ä–∞–º –±–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –≤ –ø–æ–¥–≥—Ä—É–ø–ø–µ
                    product_ids = [p.id for p in products]
                    updated_count = Product.objects.filter(
                        id__in=product_ids,
                        product_manager__isnull=True
                    ).update(product_manager=top_manager)

                    assigned_count += updated_count
                    logger.info(f"–ü–æ–¥–≥—Ä—É–ø–ø–∞ {subgroup_id}: –Ω–∞–∑–Ω–∞—á–µ–Ω –º–µ–Ω–µ–¥–∂–µ—Ä {top_manager.username} –¥–ª—è {updated_count} —Ç–æ–≤–∞—Ä–æ–≤")
                else:
                    logger.warning(f"–í –ø–æ–¥–≥—Ä—É–ø–ø–µ {subgroup_id} –Ω–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ —Å –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º–∏, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")

        logger.info(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ù–∞–∑–Ω–∞—á–µ–Ω–æ: {assigned_count} —Ç–æ–≤–∞—Ä–æ–≤")
        return f"–ù–∞–∑–Ω–∞—á–µ–Ω–æ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –¥–ª—è {assigned_count} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ {total_products} –±–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞"

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–∏ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤: {e}")
        raise